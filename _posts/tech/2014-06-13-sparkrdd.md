---
layout: post
title: 分布式内存计算框架:Spark
description: 本文介绍了通用分布式内存计算框架Spark的核心点，弹性分布式数据集（RDD，Resilient Distributed Datasets），这是一种分布式的内存抽象，允许在大型集群上执行基于内存的计算（In-Memory Computing），与此同时还保持了MapReduce等数据流模型的容错特性。
category: tech
---
##Spark原型论文

Zaharia, Matei, et al. "[Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing](https://www.usenix.org/conference/nsdi12/technical-sessions/presentation/zaharia)" Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation. USENIX Association, 2012.
[[PDF](https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf)] [[PPT](https://www.usenix.org/sites/default/files/conference/protected-files/nsdi_zaharia.pdf)][[中文翻译](http://blog.sciencenet.cn/home.php?mod=space&uid=425672&do=blog&id=520947)]

论文提出了**弹性分布式数据集（RDD，Resilient Distributed Datasets）**，这是一种分布式的内存抽象，允许在大型集群上执行基于内存的计算（In-Memory Computing），与此同时还保持了MapReduce等数据流模型的容错特性。

现有的数据流系统对两种应用的处理并不高效：一是**迭代式算法**，这在图应用和机器学习领域很常见；二是**交互式数据挖掘工具**。这两种情况下，将数据保存在内存中能够极大地提高性能。为了有效地实现**容错**，RDD提供了一种高度受限的共享内存，即RDD是**只读**的，并且**只能通过其他RDD上的批量操作来创建**。尽管如此，RDD仍然足以表示很多类型的计算，包括MapReduce和专用的迭代编程模型（如Pregel）等。论文中实现的RDD在迭代计算方面比Hadoop快二十多倍，同时还可以在5-7秒的延时内交互式地查询1TB的数据集。


第一作者[Matei Zaharia](http://people.csail.mit.edu/matei/)是[UC Berkeley AMP Lab](http://amplab.cs.berkeley.edu/)的PHD，MIT讲师，Spark母公司Databricks的创始人。
![](http://images.cnitblog.com/blog/331825/201406/131913142027574.jpg)

###背景

1. 迭代式算法的特点在于，它是给定问题y=f(x)，已知x和y，想要得到的是f的参数。所以需要从一个参数的initial值开始，扫描很多遍数据，比如说迭代100次，去逼近参数（类似数值分析中牛顿迭代法解方程的做法）。![](http://images.cnitblog.com/blog/331825/201406/131913410923427.jpg)
2. Hadoop对迭代式问题没有很好的解决，Disk－IO花费时间太多。Spark针对复杂分布式计算任务中，HDFS的反复读写特别耗时的问题，给常用数据一种共享的状态（内存的读写是TB级别的），特别适合交互式数据分析任务（对时间忍受很差），以及复杂的图算法(pagerank)![](http://images.cnitblog.com/blog/331825/201406/131914056551722.jpg)

###内存上的有效容错
1. RDD是一种抽象数据集，中间数据不用的时候不需要具象化，对RDD使用persist()/cached()函数可以使其持久化。
1. 主流的容错方法有两种 1)logging（记录细粒度update）2)快照（缺点就是代价太大）。
2. Hadoop采用数据持久化的方式进行容错，HDFS每次读写都要做replica，代价是很大的。
3. 对于Spark，内存是易失的，某个机器down掉了，内存中的RDD就没了。因此我们需要知道如果一个点failed，这个点的数据从哪里来。其采用记录RDD的血统（lineage）这种方式来进行容错，可以根据lineage来重新计算缺少的部分。lineage有五点信息，包括数据在哪，操作，优先使用什么，hash策略等。
5. 为了做容错，RDD这种数据结构有两种限制：1) immutable（只需记录lineage就可以恢复）2) 是一种paritioned collections of record，只能从coarse-grained deterministic transformations（相当于从A到B只有一种走法，不能是随机的）得到。![](http://images.cnitblog.com/blog/331825/201406/131915180772497.jpg)

###和内存数据库的区别
1. 数据库是细粒度的，每一条record的价值都很大，通常不需要统计群体的情况
2. spark是粗粒度的，是“apply same operation to many items”，一次操作中大批数据都要参与进来。对于大数据来说任意一条数据是没有意义的，群体特征才有意义。
4. 检索任务（细粒度）涉及到剪枝，分析任务（粗粒度）涉及到全盘扫描或下采样。
5. RAMCloud适合transaction事务级别（内存数据库Redis），而Spark适合做batch批处理

###Spark实例：PageRank
1. Spark可以方便地做Join操作（link和rank两张表)，而join的容错恢复是比较难的，不是narrow dependence，而是wide dependence![](http://images.cnitblog.com/blog/331825/201406/131917011557505.jpg)![](http://images.cnitblog.com/blog/331825/201406/131918217491618.jpg)![](http://images.cnitblog.com/blog/331825/201406/131918336248822.jpg)
2. Spark对用户提供了三种interface: 1) RDD 2)RDD的操作 3)RDD切分的控制。主要有两种不同类型的Flow: Data Flow(对数据进行改变，例如transformation and actions)和Control Flow(并不对数据进行改变，partitioning and persistence)![](http://images.cnitblog.com/blog/331825/201406/131916241084890.jpg)![](http://images.cnitblog.com/blog/331825/201406/131919467804739.jpg)

详细RDD操作: [SCALA ON SPARK CHEATSHEET](http://www.openkb.info/2015/01/scala-on-spark-cheatsheet.html)